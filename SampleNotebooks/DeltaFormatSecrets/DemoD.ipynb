{"cells":[{"cell_type":"code","source":["lakehouses = spark.catalog.listDatabases()\n","\n","lakehouse_list = []\n","\n","for lakehouse in lakehouses:\n","    lakehouse_list.append(lakehouse.name)\n","\n","print(lakehouse_list)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d7342a46-bfaf-4a00-a9d3-d134c0b6bd19","statement_id":3,"state":"finished","livy_statement_state":"available","queued_time":"2023-10-25T18:18:25.6364439Z","session_start_time":"2023-10-25T18:18:25.9394555Z","execution_start_time":"2023-10-25T18:18:34.6316592Z","execution_finish_time":"2023-10-25T18:18:48.5898433Z","spark_jobs":{"numbers":{"FAILED":0,"SUCCEEDED":3,"UNKNOWN":0,"RUNNING":0},"jobs":[{"displayName":"hasNext at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":10,"name":"hasNext at NativeMethodAccessorImpl.java:0","description":"Job group for statement 3:\nlakehouses = spark.catalog.listDatabases()\n\nlakehouse_list = []\n\nfor lakehouse in lakehouses:\n    lakehouse_list.append(lakehouse.name)\n\nprint(lakehouse_list)","submissionTime":"2023-10-25T18:18:46.698GMT","completionTime":"2023-10-25T18:18:46.716GMT","stageIds":[14],"jobGroup":"3","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"hasNext at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":9,"name":"hasNext at NativeMethodAccessorImpl.java:0","description":"Job group for statement 3:\nlakehouses = spark.catalog.listDatabases()\n\nlakehouse_list = []\n\nfor lakehouse in lakehouses:\n    lakehouse_list.append(lakehouse.name)\n\nprint(lakehouse_list)","submissionTime":"2023-10-25T18:18:46.660GMT","completionTime":"2023-10-25T18:18:46.688GMT","stageIds":[13],"jobGroup":"3","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"hasNext at NativeMethodAccessorImpl.java:0","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":8,"name":"hasNext at NativeMethodAccessorImpl.java:0","description":"Job group for statement 3:\nlakehouses = spark.catalog.listDatabases()\n\nlakehouse_list = []\n\nfor lakehouse in lakehouses:\n    lakehouse_list.append(lakehouse.name)\n\nprint(lakehouse_list)","submissionTime":"2023-10-25T18:18:46.617GMT","completionTime":"2023-10-25T18:18:46.640GMT","stageIds":[12],"jobGroup":"3","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"3c0e066b-4aa5-4321-96a3-52333fd7b447"},"text/plain":"StatementMeta(, d7342a46-bfaf-4a00-a9d3-d134c0b6bd19, 3, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["['MaltaLake', 'DataflowsStagingLakehouse', 'LakeBridge']\n"]}],"execution_count":1,"metadata":{},"id":"07be405a-77c4-434e-a659-6241a8aa39f2"},{"cell_type":"code","source":["for lake in lakehouse_list:\n","     tables=spark.sql(f'SHOW TABLES IN {lake}')\n","     tablenames=list(tables.toPandas()['tableName'])\n","     for tb in tablenames:\n","         print(tb)"],"outputs":[{"output_type":"display_data","data":{"application/vnd.livy.statement-meta+json":{"spark_pool":null,"session_id":"d7342a46-bfaf-4a00-a9d3-d134c0b6bd19","statement_id":4,"state":"finished","livy_statement_state":"available","queued_time":"2023-10-25T18:19:36.1058924Z","session_start_time":null,"execution_start_time":"2023-10-25T18:19:36.5514635Z","execution_finish_time":"2023-10-25T18:19:38.1602379Z","spark_jobs":{"numbers":{"FAILED":0,"SUCCEEDED":2,"UNKNOWN":0,"RUNNING":0},"jobs":[{"displayName":"toPandas at /tmp/ipykernel_8091/2021011827.py:3","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":13,"name":"toPandas at /tmp/ipykernel_8091/2021011827.py:3","description":"Job group for statement 4:\nfor lake in lakehouse_list:\n     tables=spark.sql(f'SHOW TABLES IN {lake}')\n     tablenames=list(tables.toPandas()['tableName'])\n     for tb in tablenames:\n         print(tb)","submissionTime":"2023-10-25T18:19:37.602GMT","completionTime":"2023-10-25T18:19:37.626GMT","stageIds":[16],"jobGroup":"4","status":"SUCCEEDED","numTasks":1,"numActiveTasks":0,"numCompletedTasks":1,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":1,"numActiveStages":0,"numCompletedStages":1,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}},{"displayName":"Job group for statement 4:\nfor lake in lakehouse_list:\n     tables=spark.sql(f'SHOW TABLES IN {lake}')\n     tablenames=list(tables.toPandas()['tableName'])\n     for tb in tablenames:\n         print(tb)","dataWritten":0,"dataRead":0,"rowCount":0,"usageDescription":"","jobId":12,"name":"","description":"Job group for statement 4:\nfor lake in lakehouse_list:\n     tables=spark.sql(f'SHOW TABLES IN {lake}')\n     tablenames=list(tables.toPandas()['tableName'])\n     for tb in tablenames:\n         print(tb)","submissionTime":"2023-10-25T18:19:37.452GMT","completionTime":"2023-10-25T18:19:37.452GMT","stageIds":[],"jobGroup":"4","status":"SUCCEEDED","numTasks":0,"numActiveTasks":0,"numCompletedTasks":0,"numSkippedTasks":0,"numFailedTasks":0,"numKilledTasks":0,"numCompletedIndices":0,"numActiveStages":0,"numCompletedStages":0,"numSkippedStages":0,"numFailedStages":0,"killedTasksSummary":{}}],"limit":20,"rule":"ALL_DESC"},"parent_msg_id":"a5b74767-eac4-4652-aafa-60ee14f76a41"},"text/plain":"StatementMeta(, d7342a46-bfaf-4a00-a9d3-d134c0b6bd19, 4, Finished, Available)"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["fact_sale\ndimension_city\ndimension_date\ndimension_employee\ndimension_stock_item\nTransactionHistory\n"]}],"execution_count":2,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"c9d22bff-370f-429b-8858-23dfe09c1964"},{"cell_type":"code","source":["# Welcome to your new notebook\n","# Type here in the cell editor to add code!\n","import pyarrow.dataset as pq\n","import os\n","import org.apache.spark.sql\n","\n","def cleanTables(lakename,tablename):\n","   \n","   spark.sql(f'OPTIMIZE {lakename}.{tablename} VORDER')\n","   spark.sql(f'VACUUM {lakename}.{tablename} RETAIN 0 HOURS');\n","   \n","   print(f'\\nTable {lakename}.{tablename} OPTIMIZE and VACUUM sucessfully')\n","\n","\n","def cleanLakehouse(lakeName):\n","     tables=spark.sql(f'SHOW TABLES IN {lake}')\n","     tablenames=list(tables.toPandas()['tableName'])\n","     for tb in tablenames:\n","         cleanTables(lakeName,tb)\n","\n","def listlakes():\n","   lakehouses = spark.catalog.listDatabases()\n","   lakehouse_list = []\n","   for lakehouse in lakehouses:\n","       lakehouse_list.append(lakehouse.name)\n","   return lakehouse_list\n","\n","   \n","# Test the function with a path to your delta file#\n","\n","\n","spark.conf.set(\"spark.databricks.delta.retentionDurationCheck.enabled\", \"false\")\n","\n","lakelist=listlakes()\n","\n","for lake in lakelist:\n","   cleanLakehouse(lake)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}}},"id":"17b6fe31-3dcc-467c-9270-32f1d1029b90"}],"metadata":{"language_info":{"name":"python"},"kernelspec":{"name":"synapse_pyspark","display_name":"Synapse PySpark"},"microsoft":{"host":{},"language":"python"},"widgets":{},"kernel_info":{"name":"synapse_pyspark"},"nteract":{"version":"nteract-front-end@1.0.0"},"save_output":true,"spark_compute":{"compute_id":"/trident/default","session_options":{"enableDebugMode":false,"conf":{}}},"notebook_environment":{},"synapse_widget":{"version":"0.1","state":{}},"trident":{"lakehouse":{"known_lakehouses":[{"id":"7663952e-c78d-4a3d-9c58-d539e304cb89"},{"id":"140cb3c0-34d5-4656-a072-4f2a8f50b9df"}],"default_lakehouse":"7663952e-c78d-4a3d-9c58-d539e304cb89","default_lakehouse_name":"MaltaLake","default_lakehouse_workspace_id":"f2e26421-43e7-474a-9282-89628b558c50"}}},"nbformat":4,"nbformat_minor":5}